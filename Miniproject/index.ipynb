{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-05-12T22:35:36.961527700Z",
     "start_time": "2024-05-12T22:35:34.259630600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "\n",
    "# Define folder paths\n",
    "Miniproject_dir = './Miniproject'\n",
    "resources_dir = os.path.join(Miniproject_dir, 'resources')\n",
    "\n",
    "# Create Miniproject folder if it doesn't exist\n",
    "if not os.path.exists(Miniproject_dir):\n",
    "    os.makedirs(Miniproject_dir)\n",
    "\n",
    "# Create resources folder inside Miniproject if it doesn't exist\n",
    "if not os.path.exists(resources_dir):\n",
    "    os.makedirs(resources_dir)\n",
    "\n",
    "# Load data from Wikipedia\n",
    "wiki_url = 'https://en.wikipedia.org/wiki/Healthcare_in_Denmark'\n",
    "wiki_response = requests.get(wiki_url)\n",
    "wiki_soup = BeautifulSoup(wiki_response.text, 'html.parser')\n",
    "wiki_text = wiki_soup.get_text()\n",
    "\n",
    "# Save Wikipedia text to a file\n",
    "wiki_file_path = os.path.join(resources_dir, 'wikipedia_text.txt')\n",
    "with open(wiki_file_path, 'w', encoding='utf-8') as file:\n",
    "    file.write(wiki_text)\n",
    "\n",
    "# Load data from PDF\n",
    "pdf_url = 'https://sum.dk/Media/C/A/Healthcare-in%20denmark%20an%20overview%20english-V16-dec.pdf'\n",
    "pdf_response = requests.get(pdf_url)\n",
    "pdf_file_path = os.path.join(resources_dir, 'healthcare_pdf_text.txt')\n",
    "with open(pdf_file_path, 'wb') as f:\n",
    "    f.write(pdf_response.content)\n",
    "\n",
    "pdf_text = \"\"\n",
    "with open(pdf_file_path, 'rb') as f:\n",
    "    pdf_reader = PyPDF2.PdfReader(f)\n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        pdf_text += pdf_reader.pages[page_num].extract_text()\n",
    "\n",
    "# Save PDF text to a file\n",
    "with open(pdf_file_path, 'w', encoding='utf-8') as file:\n",
    "    file.write(pdf_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "# Text processing\n\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%markdown\n",
    "# Text processing\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-05-12T22:35:36.966619500Z",
     "start_time": "2024-05-12T22:35:36.961527700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mikke\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mikke\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mikke\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Wikipedia Text:\n",
      "['healthcare', 'denmark', '', 'wikipedia', 'jump', 'content', 'main', 'menu', 'main', 'menu']\n",
      "\n",
      "Preprocessed PDF Text:\n",
      "['', 'healthcare', 'denmark', 'overview', '', 'colophon', 'healthcare', 'denmark', '', 'overview']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download NLTK resources (run only once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Define folder paths\n",
    "Miniproject_dir = 'Miniproject'\n",
    "resources_dir = os.path.join(Miniproject_dir, 'resources')\n",
    "\n",
    "# Load Wikipedia text data\n",
    "wiki_file_path = os.path.join(resources_dir, 'wikipedia_text.txt')\n",
    "with open(wiki_file_path, 'r', encoding='utf-8') as file:\n",
    "    wiki_text = file.read()\n",
    "\n",
    "# Load PDF text data\n",
    "pdf_file_path = os.path.join(resources_dir, 'healthcare_pdf_text.txt')\n",
    "with open(pdf_file_path, 'r', encoding='utf-8') as file:\n",
    "    pdf_text = file.read()\n",
    "\n",
    "# Text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove punctuation and digits\n",
    "    table = str.maketrans('', '', string.punctuation + string.digits)\n",
    "    tokens = [token.translate(table) for token in tokens]\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# Preprocess Wikipedia text\n",
    "preprocessed_wiki_text = preprocess_text(wiki_text)\n",
    "\n",
    "# Preprocess PDF text\n",
    "preprocessed_pdf_text = preprocess_text(pdf_text)\n",
    "\n",
    "# Display preprocessed text for verification\n",
    "print(\"Preprocessed Wikipedia Text:\")\n",
    "print(preprocessed_wiki_text[:10])  # Displaying first 10 tokens for brevity\n",
    "print(\"\\nPreprocessed PDF Text:\")\n",
    "print(preprocessed_pdf_text[:10])  # Displaying first 10 tokens for brevity\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-05-12T22:35:40.700509400Z",
     "start_time": "2024-05-12T22:35:36.970718700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "# Vectorization\nBag-of-words (BoW)\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%markdown\n",
    "# Vectorization\n",
    "Bag-of-words (BoW)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-05-12T22:35:40.707112100Z",
     "start_time": "2024-05-12T22:35:40.700509400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-Words Matrix Shape (Wikipedia Text): (1, 1064)\n",
      "Bag-of-Words Matrix Shape (PDF Text): (1, 1064)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the preprocessed text data\n",
    "bow_matrix_wiki = vectorizer.fit_transform([' '.join(preprocessed_wiki_text)])\n",
    "bow_matrix_pdf = vectorizer.transform([' '.join(preprocessed_pdf_text)])\n",
    "\n",
    "# Display the shape of the Bag-of-Words matrix\n",
    "print(\"Bag-of-Words Matrix Shape (Wikipedia Text):\", bow_matrix_wiki.shape)\n",
    "print(\"Bag-of-Words Matrix Shape (PDF Text):\", bow_matrix_pdf.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-05-12T22:35:40.743148700Z",
     "start_time": "2024-05-12T22:35:40.708109900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "TF-IDF (Term Frequency-Inverse Document Frequency)\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%markdown\n",
    "TF-IDF (Term Frequency-Inverse Document Frequency)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-05-12T22:35:40.744145800Z",
     "start_time": "2024-05-12T22:35:40.732995500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix Shape (Wikipedia Text): (1, 1064)\n",
      "TF-IDF Matrix Shape (PDF Text): (1, 1064)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the preprocessed text data\n",
    "tfidf_matrix_wiki = tfidf_vectorizer.fit_transform([' '.join(preprocessed_wiki_text)])\n",
    "tfidf_matrix_pdf = tfidf_vectorizer.transform([' '.join(preprocessed_pdf_text)])\n",
    "\n",
    "# Display the shape of the TF-IDF matrix\n",
    "print(\"TF-IDF Matrix Shape (Wikipedia Text):\", tfidf_matrix_wiki.shape)\n",
    "print(\"TF-IDF Matrix Shape (PDF Text):\", tfidf_matrix_pdf.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-05-12T22:35:40.784113400Z",
     "start_time": "2024-05-12T22:35:40.736497500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "# Interactive application\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%markdown\n",
    "# Interactive application"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-05-12T22:35:40.785111200Z",
     "start_time": "2024-05-12T22:35:40.759586700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.1.6 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.6)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.6) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.6) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.6) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.6) (0.6.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.6) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.18 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.6) (0.0.19)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.22 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.6) (0.1.23)\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.6) (0.0.87)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.6) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.6) (2.7.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.6) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.6) (8.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.6) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.6) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.6) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.6) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.6) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.6) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.6) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.6) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2,>=0.1.22->langchain==0.1.6) (4.3.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2,>=0.1.22->langchain==0.1.6) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.6) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.6) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.6) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain==0.1.6) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain==0.1.6) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain==0.1.6) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain==0.1.6) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.6) (3.0.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain==0.1.6) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.6) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\mikke\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community==0.0.19 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.19)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community==0.0.19) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community==0.0.19) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community==0.0.19) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community==0.0.19) (0.6.6)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.21 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community==0.0.19) (0.1.23)\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community==0.0.19) (0.0.87)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community==0.0.19) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community==0.0.19) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community==0.0.19) (8.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.19) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.19) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.19) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.19) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.19) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.19) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.19) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2,>=0.1.21->langchain-community==0.0.19) (4.3.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2,>=0.1.21->langchain-community==0.0.19) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2,>=0.1.21->langchain-community==0.0.19) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2,>=0.1.21->langchain-community==0.0.19) (2.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain-community==0.0.19) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain-community==0.0.19) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain-community==0.0.19) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain-community==0.0.19) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.0.19) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.0.19) (3.0.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.21->langchain-community==0.0.19) (1.3.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.21->langchain-community==0.0.19) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.21->langchain-community==0.0.19) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.21->langchain-community==0.0.19) (2.18.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.19) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\mikke\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core==0.1.23 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.23)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core==0.1.23) (6.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core==0.1.23) (4.3.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core==0.1.23) (1.33)\n",
      "Requirement already satisfied: langsmith<0.0.88,>=0.0.87 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core==0.1.23) (0.0.87)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core==0.1.23) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core==0.1.23) (2.7.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core==0.1.23) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core==0.1.23) (8.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3->langchain-core==0.1.23) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3->langchain-core==0.1.23) (1.3.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.1.23) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain-core==0.1.23) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain-core==0.1.23) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain-core==0.1.23) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain-core==0.1.23) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain-core==0.1.23) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain-core==0.1.23) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\mikke\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.0.9)\n",
      "Requirement already satisfied: six in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langdetect) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\mikke\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
      "Collecting transformers<5.0.0,>=4.34.0\n",
      "  Using cached transformers-4.40.2-py3-none-any.whl (9.0 MB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.66.4)\n",
      "Collecting torch>=1.11.0\n",
      "  Downloading torch-2.3.0-cp311-cp311-win_amd64.whl (159.8 MB)\n",
      "     ------------------------------------- 159.8/159.8 MB 21.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.13.0)\n",
      "Collecting huggingface-hub>=0.15.1\n",
      "  Using cached huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "Collecting Pillow\n",
      "  Downloading pillow-10.3.0-cp311-cp311-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 53.6 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1\n",
      "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Requirement already satisfied: colorama in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.10)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 47.0 MB/s eta 0:00:00\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.3-cp311-none-win_amd64.whl (287 kB)\n",
      "     ---------------------------------------- 287.3/287.3 kB ? eta 0:00:00\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Collecting intel-openmp==2021.*\n",
      "  Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Collecting tbb==2021.*\n",
      "  Using cached tbb-2021.12.0-py3-none-win_amd64.whl (286 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mikke\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Collecting mpmath>=0.19\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: tbb, mpmath, intel-openmp, sympy, safetensors, Pillow, networkx, mkl, fsspec, filelock, torch, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed Pillow-10.3.0 filelock-3.14.0 fsspec-2024.3.1 huggingface-hub-0.23.0 intel-openmp-2021.4.0 mkl-2021.4.0 mpmath-1.3.0 networkx-3.3 safetensors-0.4.3 sentence-transformers-2.7.0 sympy-1.12 tbb-2021.12.0 tokenizers-0.19.1 torch-2.3.0 transformers-4.40.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\mikke\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.1.6 \n",
    "!pip install langchain-community==0.0.19 \n",
    "!pip install langchain-core==0.1.23\n",
    "!pip install langdetect\n",
    "!pip install sentence-transformers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T22:38:55.868777800Z",
     "start_time": "2024-05-12T22:36:53.335033900Z"
    }
   },
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikke\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'csr_matrix' and 'HuggingFaceEmbeddings'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 96\u001B[0m\n\u001B[0;32m     93\u001B[0m prompt \u001B[38;5;241m=\u001B[39m PromptTemplate\u001B[38;5;241m.\u001B[39mfrom_template(template)\n\u001B[0;32m     95\u001B[0m \u001B[38;5;66;03m# Combine the TF-IDF matrices and embeddings model into a single vector\u001B[39;00m\n\u001B[1;32m---> 96\u001B[0m combined_vector \u001B[38;5;241m=\u001B[39m \u001B[43mtfidf_matrix_wiki\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtfidf_matrix_pdf\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43membeddings_model\u001B[49m\n\u001B[0;32m     98\u001B[0m \u001B[38;5;66;03m# Define a function to handle user queries\u001B[39;00m\n\u001B[0;32m     99\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhandle_query\u001B[39m(description):\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;66;03m# Detect language and handle non-English inputs\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: unsupported operand type(s) for +: 'csr_matrix' and 'HuggingFaceEmbeddings'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langdetect import detect\n",
    "\n",
    "\n",
    "\n",
    "# Define folder paths\n",
    "Miniproject_dir = 'Miniproject'\n",
    "resources_dir = os.path.join(Miniproject_dir, 'resources')\n",
    "\n",
    "# Load data from Wikipedia\n",
    "wiki_url = 'https://en.wikipedia.org/wiki/Healthcare_in_Denmark'\n",
    "wiki_response = requests.get(wiki_url)\n",
    "wiki_soup = BeautifulSoup(wiki_response.text, 'html.parser')\n",
    "wiki_text = wiki_soup.get_text()\n",
    "\n",
    "# Load PDF text data\n",
    "pdf_url = 'https://sum.dk/Media/C/A/Healthcare-in%20denmark%20an%20overview%20english-V16-dec.pdf'\n",
    "pdf_response = requests.get(pdf_url)\n",
    "pdf_text = pdf_response.text\n",
    "\n",
    "# Text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove punctuation and digits\n",
    "    tokens = [token for token in tokens if token.isalnum()]\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Preprocess Wikipedia text\n",
    "preprocessed_wiki_text = preprocess_text(wiki_text)\n",
    "\n",
    "# Preprocess PDF text\n",
    "preprocessed_pdf_text = preprocess_text(pdf_text)\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the preprocessed text data\n",
    "tfidf_matrix_wiki = tfidf_vectorizer.fit_transform([preprocessed_wiki_text])\n",
    "tfidf_matrix_pdf = tfidf_vectorizer.transform([preprocessed_pdf_text])\n",
    "\n",
    "# Initialize the embeddings model\n",
    "model_name = \"sentence-transformers/paraphrase-MiniLM-L6-v2\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": False}\n",
    "embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "# Initialize the Ollama language model\n",
    "llm = Ollama(model=\"mistral\", callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]))\n",
    "\n",
    "# Define a prompt template\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use five sentences maximum. Keep the answer as concise as possible.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Create a prompt from the template\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Combine the TF-IDF matrices and embeddings model into a single vector\n",
    "combined_vector = tfidf_matrix_wiki + tfidf_matrix_pdf + embeddings_model\n",
    "\n",
    "# Define a function to handle user queries\n",
    "def handle_query(description):\n",
    "    # Detect language and handle non-English inputs\n",
    "    if detect(description) != 'en':\n",
    "        return \"Sorry, I currently support only English descriptions.\"\n",
    "\n",
    "    # Process the description with the retrieval chain\n",
    "    response = llm({\"query\": description, \"context\": combined_vector})\n",
    "    return response[\"result\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-05-12T22:43:05.565509200Z",
     "start_time": "2024-05-12T22:42:59.581914300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2024-05-12T22:35:57.401472500Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
